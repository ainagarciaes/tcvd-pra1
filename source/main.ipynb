{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scrapy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# guardar el dataset en format csv\n",
    "def store_dataset(filename, ds):\n",
    "    ds.to_csv(filename, index=None);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_parser(URL: str):\n",
    "    req = requests.get(URL)\n",
    "    html = BeautifulSoup(req.text, 'html.parser')\n",
    "    return html\n",
    "\n",
    "def tag_a_indicadors(URL: str) -> list:\n",
    "    html = html_parser(URL)\n",
    "    indicadors = html.find('a',{'class':'dropdown-toggle'}).get('href')\n",
    "    html = html_parser(indicadors)\n",
    "    tag_a = html.find_all('a')\n",
    "    return tag_a \n",
    "\n",
    "def url_indicador(URL: str,indicadors: list, indicador: str) -> str:\n",
    "    for i, a in enumerate(indicadors):\n",
    "        if(a.text==indicador):\n",
    "            indi_url = a.get('href')\n",
    "    return URL+indi_url\n",
    "\n",
    "def busca_urls_pais(URL: str, indicador: str):\n",
    "    p = []\n",
    "    names = []\n",
    "    tag_a = tag_a_indicadors(URL)\n",
    "    indicador_url = url_indicador(URL, tag_a, indicador)\n",
    "    tag_a = html_parser(indicador_url).find_all('a')\n",
    "    #obtenim url del pais\n",
    "    for i, a in enumerate(tag_a):\n",
    "        if(' [+]' in a.text):\n",
    "            pais_url = a.get('href')\n",
    "            pais = a.text.replace(' [+]', '')\n",
    "            names.append(pais)\n",
    "            p.append(URL+pais_url)\n",
    "    \n",
    "    ret = []\n",
    "    paisos = []\n",
    "    cont = 0\n",
    "    #obtenim tots els anys\n",
    "    for precios_pais_url in p:\n",
    "        name = names[cont]\n",
    "        html = html_parser(precios_pais_url)\n",
    "        URL_list = [precios_pais_url]\n",
    "        Paisos_list = [name]\n",
    "        while len(set(URL_list))==len(URL_list):\n",
    "            url = html.find('table').find('a').get('href')\n",
    "            req = requests.get(url)\n",
    "            html = BeautifulSoup(req.text, \"html.parser\")\n",
    "            URL_list = URL_list + [url]\n",
    "            Paisos_list = Paisos_list + [name]\n",
    "            # Treiem els dos últims per què l'últim torna a ser l'any actual(per defecte) i el penúltim també\n",
    "            # és a dir, si posem un any que no existeix et torna a l'any actual\n",
    "        ret.extend(URL_list[:-2])\n",
    "        paisos.extend(Paisos_list[:-2])\n",
    "        cont = cont + 1 \n",
    "        df = pd.DataFrame()\n",
    "        df[\"url\"] = ret\n",
    "        df[\"pais\"] = paisos\n",
    "    return df\n",
    "\n",
    "def busca_url_internacional(URL: str, indicador: str) -> list:\n",
    "    tag_a = tag_a_indicadors(URL)\n",
    "    indicador_url = url_indicador(URL, tag_a, indicador)\n",
    "    html = html_parser(indicador_url)\n",
    "    URL_list = [indicador_url]\n",
    "    while len(set(URL_list))==len(URL_list):\n",
    "        url = html.find('table',{'class':'table tabledat table-striped table-condensed table-hover'}).find('a').get('href')\n",
    "        html = html_parser(url)\n",
    "        URL_list = URL_list + [url]\n",
    "    # Treiem l'últim torna a ser l'últim(per defecte)\n",
    "    return URL_list[:-1]\n",
    "\n",
    "def taula_preus(URL: list, PAIS: list) -> pd.DataFrame:\n",
    "    taula_total = pd.DataFrame()\n",
    "    # per cada url en la llista URL obtenim la taula de preus dels derivats del petroli\n",
    "    for i, url in enumerate(URL):\n",
    "        taula = pd.DataFrame()\n",
    "        dies = []\n",
    "        pr_g= []\n",
    "        derivats = []\n",
    "        html = html_parser(url)        \n",
    "        # obtenim el nom dels atributs\n",
    "        cap = html.find_all('th')\n",
    "        # obtenim l'atribut fecha i convertim a datetime\n",
    "        fechas = html.find_all('td',{'class':'fecha'})\n",
    "        for j, fecha in enumerate(fechas):\n",
    "            dia = datetime.strptime(fecha.get('data-value'), '%Y-%m-%d')\n",
    "            dies = dies + [dia]\n",
    "        # guardem a la taula\n",
    "        taula[cap[0].text] = dies  \n",
    "        # obtenim el preu dels derivats\n",
    "        preus = html.find_all('td',{'class':'numero'})\n",
    "        for j, preu in enumerate(preus):\n",
    "            pp = preu.get('data-value')\n",
    "            if (pp == ''):\n",
    "                pr = None\n",
    "            else:     \n",
    "                pr = float(pp)\n",
    "            pr_g = pr_g + [pr]\n",
    "        # generem llista per cada derivat i guardem a la taula\n",
    "        for j in range(0,6):\n",
    "            for k in range(j,len(pr_g),6):\n",
    "                derivats = derivats + [pr_g[k]]\n",
    "            taula[cap[j+1].text] = derivats\n",
    "            derivats = []\n",
    "        # agrupem cada taula \n",
    "        taula['Pais'] = PAIS[i]\n",
    "        taula_total = pd.concat([taula_total, taula], axis = 0).reset_index(drop=True)\n",
    "    return taula_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.datosmacro.com\"\n",
    "urls = busca_urls_pais(URL,'Precios al consumidor de productos petrolíferos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dataset('dades.csv', urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "taula_sp = taula_preus(urls[\"url\"], urls[\"pais\"])\n",
    "store_dataset('dades.csv', taula_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
